# Based off https://github.com/rapidsai/cudf/blob/branch-25.04/.github/workflows/pandas-tests.yaml
name: Test dask-upstream

on:
  schedule:
    # 06:15 and 08:15 UTC daily.
    # We want at least one one run after the nightly pipeline finishes.
    # https://github.com/rapidsai/workflows/blob/main/.github/workflows/nightly-pipeline-trigger.yaml is
    # currently set to 5:00 UTC and takes ~12 hours
    - cron: "15 06,18 * * *"
  workflow_dispatch:
    inputs: {}

jobs:
  setup:
    runs-on: ubuntu-latest
    outputs:
      date: ${{ steps.date.outputs.date }}
      branch: ${{ steps.branch.outputs.branch }}
    steps:
      - name: Get current date
        id: date
        run: echo "name=date::$(date +'%Y-%m-%d')" >> "$GITHUB_OUTPUT"
      - name: Get current branch
        id: branch
        run: echo "branch=${GITHUB_HEAD_REF:-${GITHUB_REF#refs/heads/}}" >> "$GITHUB_OUTPUT"
      - name: Set UV_LINK_MODE
        id: link_mode
        run: echo "LINK_MODE=copy" >> "$GITHUB_ENV"

  dask-tests:
    needs: setup
    secrets: inherit
    uses: rapidsai/shared-workflows/.github/workflows/wheels-test.yaml@branch-25.08
    with:
      # This selects "ARCH=amd64 + the latest supported Python + CUDA".
      # Pinned to 3.12 until all dependencies have wheels. Waiting for
      # - https://pypi.org/project/hdbscan/
      # matrix_filter: map(select(.ARCH == "amd64")) | group_by(.CUDA_VER|split(".")|map(tonumber)|.[0]) | map(max_by([(.PY_VER|split(".")|map(tonumber)), (.CUDA_VER|split(".")|map(tonumber))]))
      matrix_filter: map(select(.ARCH == "amd64")) | map(select(.PY_VER == "3.12")) | group_by(.CUDA_VER|split(".")|map(tonumber)|.[0]) | map(max_by([(.PY_VER|split(".")|map(tonumber)), (.CUDA_VER|split(".")|map(tonumber))]))
      build_type: nightly
      branch: ${{ needs.setup.outputs.branch }}
      date: ${{ needs.setup.outputs.date }}
      sha: ${{ github.sha }}
      script: scripts/run.sh
